{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from string import punctuation\n",
    "import sklearn.preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48574, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('TicketIncident.csv', encoding='latin-1')\n",
    "data.columns = ['v2','v1']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB Status from CA Workload Automation</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clients need to be restarted and/or powered  on</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>userLogin : userLogin Password Expired</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Service Catalog - Mobile Registration and Admi...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Boss] Can't found Income Certificate Request ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  v2 v1\n",
       "0             JOB Status from CA Workload Automation  N\n",
       "1    clients need to be restarted and/or powered  on  N\n",
       "2             userLogin : userLogin Password Expired  Y\n",
       "3  Service Catalog - Mobile Registration and Admi...  Y\n",
       "4  [Boss] Can't found Income Certificate Request ...  N"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               JOB Status from CA Workload Automation\n",
       "1      clients need to be restarted and/or powered  on\n",
       "2               userLogin : userLogin Password Expired\n",
       "3    Service Catalog - Mobile Registration and Admi...\n",
       "4    [Boss] Can't found Income Certificate Request ...\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['v2'].replace(\":\",\" \").head()\n",
    "#data['v2'].replace([^a-zA-Z ]/g, \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect',CountVectorizer()),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('clf',SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "parameter = {'tfidf_use_idf':(True,False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_search = GridSearchCV(pipeline,parameter,n_jobs=-1,verbose=1)\n",
    "print ('Performing grid search now..')\n",
    "print ('Parameters:')\n",
    "pprint(parameter)\n",
    "t0=time()\n",
    "grid_search.fit(df_incident_collection['short_description'],df_incident_collection['Automatable (Y/N)'])\n",
    "print ('done in %0.3fs'% (time()-t0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code to remove noisy words from a text\n",
    "\n",
    "noise_list = [\"is\", \"a\", \"this\", \"from\" \"...\"] \n",
    "def _remove_noise(input_text):\n",
    "    words = input_text.split() \n",
    "    noise_free_words = [  ] \n",
    "    print(word)\n",
    "    noise_free_text = \" \".join(noise_free_words) \n",
    "    return noise_free_text\n",
    "\n",
    "_remove_noise(\"this is a sample text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "s=sent_tokenize(df_incident_collection)\n",
    "for i in s:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df_incident_collection)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, df_incident_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humza\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "from sklearn import cross_validation\n",
    "data_train, data_test, labels_train, labels_test = cross_validation.train_test_split(\n",
    "    data.v2,\n",
    "    data.v1, \n",
    "    test_size = 0.2, \n",
    "    random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40               JOB Status from CA Workload Automation\n",
       "67    Service Catalog - Mobile Registration and Admi...\n",
       "15                       Chain of Custody account reset\n",
       "68    Can't found Income Certificate Request Form in...\n",
       "88               JOB Status from CA Workload Automation\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40    N\n",
       "67    Y\n",
       "15    N\n",
       "68    N\n",
       "88    N\n",
       "Name: v1, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display train labels\n",
    "labels_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80               JOB Status from CA Workload Automation\n",
       "77    lients need to have the proper group added to ...\n",
       "73         clients need to be restarted and powered  on\n",
       "94    User Receiving Proofing Oversight Task with Pr...\n",
       "33         clients need to be restarted and powered  on\n",
       "Name: v2, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display test data\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80    N\n",
       "77    N\n",
       "73    N\n",
       "94    N\n",
       "33    N\n",
       "Name: v1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display test labels\n",
    "labels_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Tf-idf vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf = True, max_df = 0.5)\n",
    "data_train_transformed = vectorizer.fit_transform(data_train)\n",
    "data_test_transformed  = vectorizer.transform(data_test)\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(data_train_transformed, labels_train)\n",
    "data_train_transformed = selector.transform(data_train_transformed).toarray()\n",
    "data_test_transformed  = selector.transform(data_test_transformed).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         0.         0.         0.         0.       ]\n",
      " [ 0.4213928  0.4213928  0.4213928  0.4213928  0.4213928]\n",
      " [ 0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.       ]\n",
      " [ 0.4213928  0.4213928  0.4213928  0.4213928  0.4213928]\n",
      " [ 0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Display the transformed data\n",
    "print(data_train_transformed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(data_train_transformed, labels_train)\n",
    "predictions = clf.predict(data_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['userlogin', 'added', 'administrators', 'their', 'the', 'local', 'proper', 'password', 'expired', 'lients', 'have', 'workload', 'with', 'email', 'from', 'ca', 'automation', 'oversight', 'job', 'access']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "indices = np.argsort(vectorizer.idf_)[::-1]\n",
    "features = vectorizer.get_feature_names()\n",
    "top_n = 20\n",
    "top_features = [features[i] for i in indices[:top_n]]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
